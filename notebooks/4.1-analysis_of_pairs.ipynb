{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educated-cleanup",
   "metadata": {},
   "source": [
    "# Analysis of drug-disease pairs\n",
    "\n",
    "This notebook summarizes the results presented in the paper and contains several methods to filter the results according to users' needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "direct-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from networkx import DiGraph, connected_components\n",
    "\n",
    "from utils import DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-finnish",
   "metadata": {},
   "source": [
    "#### Filtering functions (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accepted-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_lmax(\n",
    "    df: pd.DataFrame,\n",
    "    by_lmax: list\n",
    "):\n",
    "    \"\"\"Filter dataframe by specific lmax. \"\"\"\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=tmp_df.columns)\n",
    "    \n",
    "    for l in by_lmax:\n",
    "        fil_df = tmp_df.loc[tmp_df['lmax'] == f'lmax_{l}']\n",
    "        new_df = pd.concat([new_df, fil_df], ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thorough-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_path_occurence(\n",
    "    df: pd.DataFrame,\n",
    "    filter_num: int\n",
    "):\n",
    "    \"\"\"Filter dataframe based on number of times the pair appears in. \"\"\"\n",
    "    tmp_df = df.copy(deep=True)\n",
    "\n",
    "    tmp_df = tmp_df[['pairs', 'subgraph_name', 'lmax']]\n",
    "\n",
    "    # Collect data for each KG individually\n",
    "    custom_data = tmp_df.loc[tmp_df['subgraph_name'] == 'custom'].drop(\n",
    "        'subgraph_name',\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    custom_pairs = {}\n",
    "\n",
    "    for pair, lmax in custom_data.values:\n",
    "        if pair not in custom_pairs:\n",
    "            custom_pairs[pair] = set()\n",
    "        custom_pairs[pair].add(lmax)\n",
    "\n",
    "    opentarget_data = tmp_df.loc[tmp_df['subgraph_name'] == 'openbio'].drop(\n",
    "        'subgraph_name',\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    open_pairs = {}\n",
    "\n",
    "    for pair, lmax in opentarget_data.values:\n",
    "        if pair not in open_pairs:\n",
    "            open_pairs[pair] = set()\n",
    "        open_pairs[pair].add(lmax)\n",
    "\n",
    "    # Filter data in DF\n",
    "    index_list = []\n",
    "\n",
    "    for key, val in custom_pairs.items():\n",
    "        if len(val) > filter_num:\n",
    "            df1 = tmp_df.loc[(tmp_df['pairs'] == key) & (tmp_df['subgraph_name'] == 'custom')]\n",
    "            index_list.extend(df1.index.tolist())\n",
    "\n",
    "    for key, val in open_pairs.items():\n",
    "        if len(val) > filter_num:\n",
    "            df1 = tmp_df.loc[(tmp_df['pairs'] == key) & (tmp_df['subgraph_name'] == 'openbio')]\n",
    "            index_list.extend(df1.index.tolist())\n",
    "\n",
    "    index_to_keep = sorted(list(set(index_list)))\n",
    "\n",
    "    new_df = df[df.index.isin(index_to_keep)]\n",
    "\n",
    "    print(f'Reduced dataframe from {df.shape} to {new_df.shape}')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "yellow-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_node_count(\n",
    "    df: pd.DataFrame,\n",
    "    min_count: int,\n",
    "    max_count: int = 0\n",
    "):\n",
    "    \"\"\"Filter dataframe according to the number of unique nodes between drug-disease pair. \"\"\"\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    \n",
    "    if max_count == 0:\n",
    "        return tmp_df.loc[tmp_df['number_of_unique_nodes'] > min_count]\n",
    "    else:\n",
    "        return tmp_df.loc[tmp_df['number_of_unique_nodes'].between(min_count, max_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessory-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_concordant_path(\n",
    "    df: pd.DataFrame,\n",
    "    min_count: int,\n",
    "    max_count: int = 0\n",
    "):\n",
    "    \"\"\"Filtere dataframe based on number of concordant_paths between drug-disease pair. \"\"\"\n",
    "    tmp_df = df.copy(deep=True)\n",
    "\n",
    "    if max_count == 0:\n",
    "        return tmp_df.loc[tmp_df['number_of_concordant_paths'] > min_count]\n",
    "    else:\n",
    "        return tmp_df.loc[tmp_df['number_of_concordant_paths'].between(min_count, max_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-asthma",
   "metadata": {},
   "source": [
    "#### Filter function main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affecting-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(\n",
    "    df_list: list, \n",
    "    filter_num: int = 0, \n",
    "    min_node_count: int = 0,\n",
    "    max_node_count: int = 0,\n",
    "    max_path_count:int = 0,\n",
    "    min_path_count:int = 0,\n",
    "    lmax_list: list = []\n",
    "):     \n",
    "    final_df = []\n",
    "    \n",
    "    for df in df_list:\n",
    "        current_df = df\n",
    "        if len(lmax_list) > 0:\n",
    "            current_df = filter_by_lmax(current_df, by_lmax=lmax_list)\n",
    "            \n",
    "        if min_node_count != 0:\n",
    "            current_df = filter_by_node_count(\n",
    "                current_df,\n",
    "                min_count=min_node_count,\n",
    "                max_count=max_node_count\n",
    "            )\n",
    "            \n",
    "        if min_path_count != 0:\n",
    "            current_df = filter_by_concordant_path(\n",
    "                current_df, \n",
    "                max_count=max_path_count, \n",
    "                min_count=min_path_count\n",
    "            )\n",
    "                \n",
    "        if filter_num != 0:\n",
    "            current_df = filter_by_path_occurence(current_df, filter_num)\n",
    "        \n",
    "        final_df.append(current_df)\n",
    "            \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-cleanup",
   "metadata": {},
   "source": [
    "#### Precision that can be achieved by chance for each gold standard data (From Notebook 5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "driving-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_dict = {\n",
    "    'openbio':  {\n",
    "        'creed_target': 26.1649,\n",
    "        'creed_geo': 36.7742,\n",
    "        'lc1000_target': 11.3169,\n",
    "        'lc1000_geo': 15.6614,\n",
    "    },\n",
    "    'custom': {\n",
    "        'creed_target': 24.359,\n",
    "        'creed_geo': 33.5294,\n",
    "        'lc1000_target': 9.23336,\n",
    "        'lc1000_geo': 12.8342,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-peripheral",
   "metadata": {},
   "source": [
    "#### Calculate precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bridal-lighting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cal_trial_info(df_list, trial_value_dict, data_col):\n",
    "    \n",
    "    info_df = pd.DataFrame(columns=[\n",
    "        'dataset',\n",
    "        'subgraph',\n",
    "        'precision',\n",
    "        'value by chance',\n",
    "        'pair_count'\n",
    "    ])\n",
    "    \n",
    "    for df in df_list:\n",
    "        for gname in ['openbio', 'custom']:\n",
    "            if df.empty:\n",
    "                continue\n",
    "                \n",
    "            new_df = df.loc[df['subgraph_name'] == gname]\n",
    "            \n",
    "            if new_df.empty:\n",
    "                data_set = df['dataset'].unique().tolist()[0]\n",
    "                trial_dict = {True: set(), False: set()}\n",
    "                percent = ''\n",
    "            else:\n",
    "                data_set = new_df['dataset'].unique().tolist()[0]\n",
    "                \n",
    "                trial_dict = {True: set(), False: set()}\n",
    "                for bool_val, pair in new_df[[data_col, 'pairs']].values:\n",
    "                    trial_dict[bool_val].add(pair)\n",
    "                \n",
    "                # Convert back to list\n",
    "                trial_dict[True] = list(trial_dict[True])\n",
    "                trial_dict[False] = list(trial_dict[False])\n",
    "                \n",
    "                percent = len(trial_dict[True])/(len(trial_dict[True]) + len(trial_dict[False])) * 100\n",
    "            \n",
    "            gdict = trial_value_dict[gname]\n",
    "                        \n",
    "            # Get binomial p-value\n",
    "            true_positive = len(trial_dict[True])\n",
    "            all_positives = (len(trial_dict[True]) + len(trial_dict[False]))\n",
    "            trial_val = round(gdict[data_set], 3) / 100\n",
    "            \n",
    "            tmp = pd.DataFrame({\n",
    "                'dataset': data_set,\n",
    "                'subgraph': gname,\n",
    "                'precision': round(percent, 3) if type(percent) == float else percent, \n",
    "                'value by chance': round(gdict[data_set], 3),\n",
    "                'pair_count': f'{true_positive}/{all_positives}'\n",
    "            }, index=[0])\n",
    "            info_df = pd.concat([info_df, tmp], ignore_index=True)\n",
    "            \n",
    "    return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "secondary-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_ending: str, trial_dict: dict, col_name: str):\n",
    "    k = []\n",
    "    \n",
    "    for file in os.listdir(os.path.join(DATA_DIR, 'concordant_paths')):\n",
    "        if file.endswith(file_ending):\n",
    "            df = pd.read_csv(\n",
    "                os.path.join(DATA_DIR, 'concordant_paths', file),\n",
    "                sep='\\t'\n",
    "            )\n",
    "\n",
    "            data_set = file.split('-')[0]\n",
    "            df['dataset'] = data_set\n",
    "\n",
    "            df['pairs'] = df['source'] + '_' + df['target']\n",
    "\n",
    "            k.append(df)\n",
    "            \n",
    "    filtered_df = filter_df(df_list=k)\n",
    "    \n",
    "    m = cal_trial_info(\n",
    "        df_list=filtered_df, \n",
    "        trial_value_dict=trial_dict, \n",
    "        data_col=col_name\n",
    "    )\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "affecting-recipient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>subgraph</th>\n",
       "      <th>precision</th>\n",
       "      <th>value by chance</th>\n",
       "      <th>pair_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lc1000_geo</td>\n",
       "      <td>openbio</td>\n",
       "      <td>80.000</td>\n",
       "      <td>15.661</td>\n",
       "      <td>4/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lc1000_geo</td>\n",
       "      <td>custom</td>\n",
       "      <td>66.667</td>\n",
       "      <td>12.834</td>\n",
       "      <td>2/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lc1000_target</td>\n",
       "      <td>openbio</td>\n",
       "      <td>54.545</td>\n",
       "      <td>11.317</td>\n",
       "      <td>6/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lc1000_target</td>\n",
       "      <td>custom</td>\n",
       "      <td>50.000</td>\n",
       "      <td>9.233</td>\n",
       "      <td>2/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>creed_geo</td>\n",
       "      <td>openbio</td>\n",
       "      <td>50.000</td>\n",
       "      <td>36.774</td>\n",
       "      <td>1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>creed_geo</td>\n",
       "      <td>custom</td>\n",
       "      <td>50.000</td>\n",
       "      <td>33.529</td>\n",
       "      <td>1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>creed_target</td>\n",
       "      <td>openbio</td>\n",
       "      <td>50.000</td>\n",
       "      <td>26.165</td>\n",
       "      <td>1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>creed_target</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.359</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset subgraph  precision  value by chance pair_count\n",
       "0     lc1000_geo  openbio     80.000           15.661        4/5\n",
       "1     lc1000_geo   custom     66.667           12.834        2/3\n",
       "2  lc1000_target  openbio     54.545           11.317       6/11\n",
       "3  lc1000_target   custom     50.000            9.233        2/4\n",
       "4      creed_geo  openbio     50.000           36.774        1/2\n",
       "5      creed_geo   custom     50.000           33.529        1/2\n",
       "6   creed_target  openbio     50.000           26.165        1/2\n",
       "7   creed_target   custom      0.000           24.359        0/1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = main(\n",
    "    file_ending='-results.tsv',\n",
    "    trial_dict=clinical_dict,\n",
    "    col_name='in_clinical_trial'\n",
    ")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-threshold",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
