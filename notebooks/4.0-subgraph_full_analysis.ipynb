{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "environmental-guarantee",
   "metadata": {},
   "source": [
    "# Subgraph Full Analysis\n",
    "\n",
    "This notebook conatins selection of concordant paths based on both drug and disease transcription data of all chemical-disease pairs in our subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-enlargement",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "documentary-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from networkx import DiGraph\n",
    "\n",
    "from utils import (get_paths, filter_dataset, get_validated_paths, create_graph_from_df,\n",
    "                   get_path_count, DATA_DIR, KG_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuck-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger('drug2ways').setLevel(logging.CRITICAL)\n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-animal",
   "metadata": {},
   "source": [
    "# Load dataset-generated network dataframe - Unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "included-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "openbiolink_df = pd.read_csv(\n",
    "#     os.path.join(KG_DATA_PATH, 'shuffled_openbiolink.tsv'),\n",
    "    'shuffled_openbiolink_kg.tsv',\n",
    "    sep='\\t'\n",
    ")\n",
    "openbiolink_df.rename(columns={\"relation\": \"polarity\"}, inplace=True)\n",
    "\n",
    "custom_df = pd.read_csv(\n",
    "#     os.path.join(KG_DATA_PATH, 'shuffled_custom.tsv'),\n",
    "    'shuffled_custom_kg.tsv',\n",
    "    sep='\\t'\n",
    ")\n",
    "custom_df.rename(columns={\"relation\": \"polarity\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-membrane",
   "metadata": {},
   "source": [
    "openbiolink_df = pd.read_csv(\n",
    "    os.path.join(KG_DATA_PATH, 'openbiolink_filtered_kg.tsv'),\n",
    "    sep='\\t'\n",
    ")\n",
    "openbiolink_df.rename(columns={\"relation\": \"polarity\"}, inplace=True)\n",
    "\n",
    "custom_df = pd.read_csv(\n",
    "    os.path.join(KG_DATA_PATH, 'custom_filtered_kg.tsv'),\n",
    "    sep='\\t'\n",
    ")\n",
    "custom_df.rename(columns={\"relation\": \"polarity\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-north",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-franklin",
   "metadata": {},
   "source": [
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'creed_harmonized_expression.json')) as file:\n",
    "    creed_dict = json.load(file)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'geo_harmonized_expression.json')) as file2:\n",
    "    geo_dict = json.load(file2)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'lc1000_harmonized_expression.json')) as file3:\n",
    "    lc1000_dict = json.load(file3)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'target_harmonized_expression.json')) as file4:\n",
    "    open_target_dict = json.load(file4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compact-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'creed_permuted.json')) as file:\n",
    "    creed_dict = json.load(file)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'geo_permuted.json')) as file2:\n",
    "    geo_dict = json.load(file2)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'lc1000_permuted.json')) as file3:\n",
    "    lc1000_dict = json.load(file3)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'target_permuted.json')) as file4:\n",
    "    open_target_dict = json.load(file4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-diesel",
   "metadata": {},
   "source": [
    "# Filterting dataset based on network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conditional-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREED\n",
    "creed_openbio = filter_dataset(dataset=creed_dict, graph_df=openbiolink_df)\n",
    "creed_custom = filter_dataset(dataset=creed_dict, graph_df=custom_df)\n",
    "\n",
    "creed_dict = {'openbio': creed_openbio, 'custom': creed_custom}\n",
    "\n",
    "# GEO\n",
    "geo_openbio = filter_dataset(dataset=geo_dict, graph_df=openbiolink_df)\n",
    "geo_custom = filter_dataset(dataset=geo_dict, graph_df=custom_df)\n",
    "\n",
    "geo_dict = {'openbio': geo_openbio, 'custom': geo_custom}\n",
    "\n",
    "# OpenTarget\n",
    "target_openbio = filter_dataset(dataset=open_target_dict, graph_df=openbiolink_df)\n",
    "target_custom = filter_dataset(dataset=open_target_dict, graph_df=custom_df)\n",
    "\n",
    "open_target_dict = {'openbio': target_openbio, 'custom': target_custom}\n",
    "\n",
    "# Lc1000\n",
    "lc1000_openbio = filter_dataset(dataset=lc1000_dict, graph_df=openbiolink_df)\n",
    "lc1000_custom = filter_dataset(dataset=lc1000_dict, graph_df=custom_df)\n",
    "\n",
    "lc1000_dict = {'openbio': lc1000_openbio, 'custom': lc1000_custom}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-somalia",
   "metadata": {},
   "source": [
    "# Load clinical and drug-indication data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "settled-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'gold-standard', 'clinical-trial.json')) as file:\n",
    "    clinical_dict = json.load(file).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-gross",
   "metadata": {},
   "source": [
    "# Creating information dict for each chemical-disease pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "atmospheric-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = {\n",
    "    'creed' : creed_dict,\n",
    "    'target': open_target_dict,\n",
    "    'geo': geo_dict,\n",
    "    'lc1000': lc1000_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-tower",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### creed-target ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting paths: 100%|██████████| 620/620 [13:55<00:00,  1.35s/it]\n",
      "Calculating concordance: 100%|██████████| 3/3 [02:38<00:00, 52.87s/it]\n",
      "Getting paths: 100%|██████████| 1170/1170 [03:52<00:00,  5.02it/s]\n",
      "Calculating concordance: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### creed-geo ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting paths: 100%|██████████| 310/310 [04:46<00:00,  1.08it/s]\n",
      "Calculating concordance: 100%|██████████| 3/3 [00:47<00:00, 15.76s/it]\n",
      "Getting paths: 100%|██████████| 510/510 [01:51<00:00,  4.56it/s]\n",
      "Calculating concordance: 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### lc1000-target ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting paths:  91%|█████████▏| 3495/3820 [36:29<13:41,  2.53s/it]  "
     ]
    }
   ],
   "source": [
    "for c, d in product(['creed', 'lc1000'], ['target', 'geo']):\n",
    "    graph_name = c + '_' + d\n",
    "    \n",
    "    print(f'### {c}-{d} ###')\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\n",
    "        'source',\n",
    "        'target',\n",
    "        'number_of_paths',\n",
    "        'number_of_concordant_paths',\n",
    "        'in_clinical_trial',\n",
    "        'number_of_concordant_activatory_paths',\n",
    "        'number_of_concordant_inhibitory_paths',\n",
    "        'subgraph_size',\n",
    "        'number_of_unique_nodes',\n",
    "        'lmax',\n",
    "        'subgraph_name',\n",
    "    ])\n",
    "    \n",
    "    if not os.path.exists(os.path.join(DATA_DIR, 'concordant_paths')):\n",
    "        os.mkdir(os.path.join(DATA_DIR, 'concordant_paths'))\n",
    "    \n",
    "    for gname in ['openbio', 'custom']:\n",
    "        if gname == 'openbio':\n",
    "            graph = create_graph_from_df(openbiolink_df)\n",
    "            kg = graph.copy()\n",
    "        else:\n",
    "            graph = create_graph_from_df(custom_df)\n",
    "            kg = graph.copy()\n",
    "        \n",
    "        paths = get_paths(\n",
    "            graph=kg,\n",
    "            disease_dict=MAP[d][gname],\n",
    "            chemical_dict=MAP[c][gname],\n",
    "        )\n",
    "        \n",
    "        # Iterating different chemical-disease pair\n",
    "        for lmax, p_dict in tqdm(paths.items(), desc='Calculating concordance'):\n",
    "            for p in p_dict:\n",
    "                if len(p['paths']) > 0:\n",
    "\n",
    "                    # Just get the nodes from the path without relations\n",
    "                    tmp_paths = []\n",
    "\n",
    "                    for v, l in p['paths'].items():\n",
    "                        pth = []\n",
    "                        for k in l:\n",
    "                            if k in ['-|', '->']:\n",
    "                                continue\n",
    "                            else:\n",
    "                                pth.append(k)\n",
    "                        tmp_paths.append(pth)\n",
    "\n",
    "                    chemical = p['source']\n",
    "                    disease = p['target']\n",
    "\n",
    "\n",
    "                    results = get_validated_paths(\n",
    "                        directed_graph=kg,\n",
    "                        source=chemical,\n",
    "                        target=disease,\n",
    "                        all_paths=tmp_paths,\n",
    "                        drug_dict=MAP[c][gname][chemical],\n",
    "                        disease_dict=MAP[d][gname][disease],\n",
    "                        clinical_pair_dict=clinical_dict,\n",
    "                    )\n",
    "\n",
    "                    if results['number_of_concordant_paths'] != 0:\n",
    "                        new_results = {\n",
    "                            'source': results['source'],\n",
    "                            'target': results['target'],\n",
    "                            'number_of_paths': results['number_of_paths'],\n",
    "                            'number_of_concordant_paths': results['number_of_concordant_paths'],\n",
    "                            'in_clinical_trial': results['in_clinical_trial'],\n",
    "                            'number_of_concordant_activatory_paths': results['number_of_concordant_activatory_paths'],\n",
    "                            'number_of_concordant_inhibitory_paths': results['number_of_concordant_inhibitory_paths'],\n",
    "                            'subgraph_size': results['subgraph_size'],\n",
    "                            'number_of_unique_nodes': results['number_of_unique_nodes'],\n",
    "                            'lmax': lmax,\n",
    "                            'subgraph_name': gname,\n",
    "                        }\n",
    "\n",
    "                        tmp_df = pd.DataFrame(new_results, index=[0])\n",
    "                        df = pd.concat(\n",
    "                            [df, tmp_df],\n",
    "                            ignore_index=True\n",
    "                        )\n",
    "\n",
    "    n_file_path = os.path.join(DATA_DIR, 'concordant_paths', f'{graph_name}-permuted.tsv')\n",
    "    df.to_csv(n_file_path, sep='\\t', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-highway",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
