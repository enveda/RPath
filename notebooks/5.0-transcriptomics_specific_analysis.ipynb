{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "environmental-guarantee",
   "metadata": {},
   "source": [
    "# Transcriptomics-specific Analysis\n",
    "\n",
    "This notebook contains creation of all chemical-disease pairs in our subgraphs based on specific-transcriptomic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-sessions",
   "metadata": {},
   "source": [
    "# Pre-requirements\n",
    "\n",
    "1. Installation of drug2ways\n",
    "1. Running of earlier notebook (notebook 2,3, and 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-enlargement",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "documentary-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from networkx import DiGraph\n",
    "\n",
    "from utils import (get_paths, filter_dataset, \n",
    "                   get_transcriptomic_paths, create_graph_from_df,\n",
    "                   get_path_count, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuck-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger('drug2ways').setLevel(logging.CRITICAL)\n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-animal",
   "metadata": {},
   "source": [
    "# Load dataset-generated network dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "widespread-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "openbiolink_path = os.path.join(DATA_DIR, 'kg', 'normalized', 'openbiolink_kg_normalized.tsv')\n",
    "custom_path = os.path.join(DATA_DIR, 'kg', 'normalized', 'custom_kg_normalized.tsv')\n",
    "\n",
    "# Load DF\n",
    "openbiolink_df = pd.read_csv(openbiolink_path, sep='\\t')\n",
    "openbiolink_df.rename(columns={'relation': 'polarity'}, inplace=True)\n",
    "\n",
    "custom_df = pd.read_csv(custom_path, sep='\\t')\n",
    "custom_df.rename(columns={'relation': 'polarity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-north",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verified-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'creeds', 'normalized', 'harmonized_expression.json')) as file:\n",
    "    creed_dict = json.load(file)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'geo', 'normalized', 'harmonized_expression.json')) as file2:\n",
    "    geo_dict = json.load(file2)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'l1000', 'normalized', 'harmonized_expression.json')) as file3:\n",
    "    l1000_dict = json.load(file3)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'open_targets', 'normalized', 'harmonized_expression.json')) as file4:\n",
    "    open_target_dict = json.load(file4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-diesel",
   "metadata": {},
   "source": [
    "# Filterting dataset based on network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conditional-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREED\n",
    "creed_openbio = filter_dataset(dataset=creed_dict, graph_df=openbiolink_df)\n",
    "creed_custom = filter_dataset(dataset=creed_dict, graph_df=custom_df)\n",
    "\n",
    "creed_dict = {'openbio': creed_openbio, 'custom': creed_custom}\n",
    "\n",
    "# GEO\n",
    "geo_openbio = filter_dataset(dataset=geo_dict, graph_df=openbiolink_df)\n",
    "geo_custom = filter_dataset(dataset=geo_dict, graph_df=custom_df)\n",
    "\n",
    "geo_dict = {'openbio': geo_openbio, 'custom': geo_custom}\n",
    "\n",
    "# OpenTarget\n",
    "target_openbio = filter_dataset(dataset=open_target_dict, graph_df=openbiolink_df)\n",
    "target_custom = filter_dataset(dataset=open_target_dict, graph_df=custom_df)\n",
    "\n",
    "open_target_dict = {'openbio': target_openbio, 'custom': target_custom}\n",
    "\n",
    "# L1000\n",
    "l1000_openbio = filter_dataset(dataset=l1000_dict, graph_df=openbiolink_df)\n",
    "l1000_custom = filter_dataset(dataset=l1000_dict, graph_df=custom_df)\n",
    "\n",
    "l1000_dict = {'openbio': l1000_openbio, 'custom': l1000_custom}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-somalia",
   "metadata": {},
   "source": [
    "# Load clinical and drug-indication data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "settled-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'gold-standard', 'filtered-clinical-pairs.json')) as file:\n",
    "    clinical_pair_dict = json.load(file).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aggressive-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'gold-standard', 'filtered-indications.json')) as file:\n",
    "    indication_pair_dict = json.load(file).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-grocery",
   "metadata": {},
   "source": [
    "# Analysis path for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-prompt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "environmental-gross",
   "metadata": {},
   "source": [
    "# Creating information dict for each chemical-disease pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atmospheric-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = {\n",
    "    'creed' : creed_dict,\n",
    "    'target': open_target_dict,\n",
    "    'geo': geo_dict,\n",
    "    'l1000': l1000_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "marked-tower",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading graph: 100%|██████████| 48878/48878 [00:00<00:00, 385178.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creed_target\n",
      "### creed-target ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4512/4512 [06:53<00:00, 10.90it/s]\n",
      "Calculating concordance: 100%|██████████| 5/5 [00:07<00:00,  1.57s/it]\n",
      "Loading graph: 100%|██████████| 52182/52182 [00:00<00:00, 376019.08it/s]\n",
      "100%|██████████| 1925/1925 [08:20<00:00,  3.84it/s]\n",
      "Calculating concordance: 100%|██████████| 5/5 [00:24<00:00,  4.81s/it]\n",
      "Loading graph: 100%|██████████| 48878/48878 [00:00<00:00, 424284.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creed_geo\n",
      "### creed-geo ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1728/1728 [02:50<00:00, 10.12it/s]\n",
      "Calculating concordance: 100%|██████████| 5/5 [00:13<00:00,  2.72s/it]\n",
      "Loading graph: 100%|██████████| 52182/52182 [00:00<00:00, 392322.96it/s]\n",
      "100%|██████████| 935/935 [05:23<00:00,  2.89it/s]\n",
      "Calculating concordance: 100%|██████████| 5/5 [00:49<00:00,  9.87s/it]\n",
      "Loading graph: 100%|██████████| 48878/48878 [00:00<00:00, 416777.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1000_target\n",
      "### l1000-target ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37788/37788 [30:02<00:00, 20.96it/s]  \n",
      "Calculating concordance: 100%|██████████| 5/5 [00:22<00:00,  4.51s/it]\n",
      "Loading graph: 100%|██████████| 52182/52182 [00:00<00:00, 358597.00it/s]\n",
      "100%|██████████| 10220/10220 [49:03<00:00,  3.47it/s] \n",
      "Calculating concordance: 100%|██████████| 5/5 [03:01<00:00, 36.26s/it]\n",
      "Loading graph: 100%|██████████| 48878/48878 [00:00<00:00, 345137.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1000_geo\n",
      "### l1000-geo ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14472/14472 [13:36<00:00, 17.73it/s] \n",
      "Calculating concordance: 100%|██████████| 5/5 [00:56<00:00, 11.31s/it]\n",
      "Loading graph: 100%|██████████| 52182/52182 [00:00<00:00, 398025.71it/s]\n",
      "100%|██████████| 4964/4964 [28:39<00:00,  2.89it/s]  \n",
      "Calculating concordance: 100%|██████████| 5/5 [05:00<00:00, 60.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for c, d in product(['creed', 'l1000'], ['target', 'geo']):\n",
    "    c_set = MAP[c]\n",
    "    d_set = MAP[d]\n",
    "    graph_name = c + '_' + d\n",
    "    print(graph_name)\n",
    "    \n",
    "    print(f'### {c}-{d} ###')\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\n",
    "        'source',\n",
    "        'target',\n",
    "        'number_of_paths',\n",
    "        'number_of_concordant_paths',\n",
    "        'in_clinical_trial',\n",
    "        'in_drug_indication',\n",
    "        'number_of_concordant_activatory_paths',\n",
    "        'number_of_concordant_inhibitory_paths',\n",
    "        'subgraph_size',\n",
    "        'number_of_unique_nodes',\n",
    "        'lmax',\n",
    "        'subgraph_name',\n",
    "    ])\n",
    "    \n",
    "    if not os.path.exists(os.path.join(DATA_DIR, 'concordant_paths')):\n",
    "        os.mkdir(os.path.join(DATA_DIR, 'concordant_paths'))\n",
    "    \n",
    "    NAME = f'{graph_name}-.tsv'\n",
    "    file_path = os.path.join(DATA_DIR, 'concordant_paths', NAME)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        continue\n",
    "        \n",
    "    # Iterating different chemical-disease pair\n",
    "    final_data = {\n",
    "        'drug': df,\n",
    "        'disease': df\n",
    "    }\n",
    "        \n",
    "    for gname in ['openbio', 'custom']:\n",
    "        if gname == 'openbio':\n",
    "            flag = True\n",
    "            kg_df = openbiolink_df\n",
    "        else:\n",
    "            flag = False\n",
    "            kg_df = custom_df\n",
    "        \n",
    "        paths = get_paths(\n",
    "            graph_df=kg_df,\n",
    "            disease_dict=d_set[gname],\n",
    "            chemical_dict=c_set[gname],\n",
    "            graph_name=graph_name,\n",
    "            openbio=flag\n",
    "        )\n",
    "        \n",
    "        if paths is None:\n",
    "            continue\n",
    "        \n",
    "        graph_copy = create_graph_from_df(kg_df)\n",
    "        graph = graph_copy.copy()\n",
    "\n",
    "        for lmax, p_dict in tqdm(paths.items(), desc='Calculating concordance'):\n",
    "            for p in p_dict:\n",
    "                if len(p['paths']) > 0:\n",
    "                    # Just get the nodes from the path\n",
    "                    tmp_paths = []\n",
    "                    for v, l in p['paths'].items():\n",
    "                        pth = []\n",
    "                        for k in l:\n",
    "                            if k in ['-|', '->']:\n",
    "                                continue\n",
    "                            else:\n",
    "                                pth.append(k)\n",
    "                        tmp_paths.append(pth)\n",
    "\n",
    "                    chemical = p['source']\n",
    "                    disease = p['target']\n",
    "\n",
    "                    results = get_transcriptomic_paths(\n",
    "                        directed_graph=graph,\n",
    "                        source=chemical,\n",
    "                        target=disease,\n",
    "                        all_paths=tmp_paths,\n",
    "                        drug_dict=c_set[gname][chemical],\n",
    "                        disease_dict=d_set[gname][disease],\n",
    "                        clinical_pair_dict=clinical_pair_dict,\n",
    "                        drug_indication_dict=indication_pair_dict,\n",
    "                    )\n",
    "                    \n",
    "                    # For drug data\n",
    "                    for i in ['drug_paths', 'disease_paths']:\n",
    "                        concordant_num = len(results[i])\n",
    "                        if concordant_num != 0:\n",
    "                            activated_paths, inhibited_paths = get_path_count(\n",
    "                                directed_graph=graph,\n",
    "                                filtered_paths=results[i]\n",
    "                            )\n",
    "                            \n",
    "                            new_results = {\n",
    "                                'source': results['source'],\n",
    "                                'target': results['target'],\n",
    "                                'number_of_paths': results['number_of_paths'],\n",
    "                                'number_of_concordant_paths': concordant_num,\n",
    "                                'in_clinical_trial': results['in_clinical_trial'],\n",
    "                                'in_drug_indication': results['in_drug_indication'],\n",
    "                                'number_of_concordant_activatory_paths': activated_paths,\n",
    "                                'number_of_concordant_inhibitory_paths': inhibited_paths,\n",
    "                                'subgraph_size': results['subgraph_size'],\n",
    "                                'number_of_unique_nodes': results['number_of_unique_nodes'],\n",
    "                                'lmax': lmax,\n",
    "                                'subgraph_name': gname,\n",
    "                            }\n",
    "\n",
    "                            tmp_df = pd.DataFrame(new_results, index=[0])\n",
    "                            if i == 'drug_paths':\n",
    "                                final_data['drug'] = pd.concat(\n",
    "                                    [final_data['drug'], tmp_df],\n",
    "                                    ignore_index=True\n",
    "                                )\n",
    "                            else:\n",
    "                                final_data['disease'] = pd.concat(\n",
    "                                    [final_data['disease'], tmp_df],\n",
    "                                    ignore_index=True\n",
    "                                )\n",
    "                        \n",
    "    for i, val in final_data.items():\n",
    "        n_file_path = os.path.join(DATA_DIR, 'concordant_paths', f'{graph_name}-{i}.tsv')\n",
    "        val.to_csv(n_file_path, sep='\\t', index=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
