{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "environmental-guarantee",
   "metadata": {},
   "source": [
    "# Transcriptomics-specific Analysis\n",
    "\n",
    "This notebook contains creation of all chemical-disease pairs in our subgraphs based on specific-transcriptomic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-sessions",
   "metadata": {},
   "source": [
    "# Pre-requirements\n",
    "\n",
    "1. Installation of drug2ways\n",
    "1. Running of earlier notebook (notebook 2,3, and 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-enlargement",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from networkx import DiGraph\n",
    "\n",
    "from utils import (get_paths, filter_dataset, \n",
    "                   get_transcriptomic_paths, create_graph_from_df,\n",
    "                   get_path_count, DATA_DIR, KG_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger('drug2ways').setLevel(logging.CRITICAL)\n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-animal",
   "metadata": {},
   "source": [
    "# Load dataset-generated network dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "openbiolink_df = pd.read_csv(\n",
    "    os.path.join(KG_DATA_PATH, 'openbiolink_filtered_kg.tsv'),\n",
    "    sep='\\t'\n",
    ")\n",
    "\n",
    "custom_df = pd.read_csv(\n",
    "    os.path.join(KG_DATA_PATH, 'custom_filtered_kg.tsv'), \n",
    "    sep='\\t'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-north",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'harmonized_expression.json')) as file:\n",
    "    creed_dict = json.load(file)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'harmonized_expression.json')) as file2:\n",
    "    geo_dict = json.load(file2)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'harmonized_expression.json')) as file3:\n",
    "    lc1000_dict = json.load(file3)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'transcriptomics', 'harmonized_expression.json')) as file4:\n",
    "    open_target_dict = json.load(file4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-diesel",
   "metadata": {},
   "source": [
    "# Filterting dataset based on network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREED\n",
    "creed_openbio = filter_dataset(dataset=creed_dict, graph_df=openbiolink_df)\n",
    "creed_custom = filter_dataset(dataset=creed_dict, graph_df=custom_df)\n",
    "\n",
    "creed_dict = {'openbio': creed_openbio, 'custom': creed_custom}\n",
    "\n",
    "# GEO\n",
    "geo_openbio = filter_dataset(dataset=geo_dict, graph_df=openbiolink_df)\n",
    "geo_custom = filter_dataset(dataset=geo_dict, graph_df=custom_df)\n",
    "\n",
    "geo_dict = {'openbio': geo_openbio, 'custom': geo_custom}\n",
    "\n",
    "# OpenTarget\n",
    "target_openbio = filter_dataset(dataset=open_target_dict, graph_df=openbiolink_df)\n",
    "target_custom = filter_dataset(dataset=open_target_dict, graph_df=custom_df)\n",
    "\n",
    "open_target_dict = {'openbio': target_openbio, 'custom': target_custom}\n",
    "\n",
    "# L1000\n",
    "lc1000_openbio = filter_dataset(dataset=lc1000_dict, graph_df=openbiolink_df)\n",
    "lc1000_custom = filter_dataset(dataset=lc1000_dict, graph_df=custom_df)\n",
    "\n",
    "lc1000_dict = {'openbio': lc1000_openbio, 'custom': lc1000_custom}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-somalia",
   "metadata": {},
   "source": [
    "# Load clinical and drug-indication data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'gold-standard', 'filtered-clinical-pairs.json')) as file:\n",
    "    clinical_pair_dict = json.load(file).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-gross",
   "metadata": {},
   "source": [
    "# Creating information dict for each chemical-disease pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = {\n",
    "    'creed' : creed_dict,\n",
    "    'target': open_target_dict,\n",
    "    'geo': geo_dict,\n",
    "    'lc1000': lc1000_dict,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-tower",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c, d in product(['creed', 'lc1000'], ['target', 'geo']):\n",
    "    c_set = MAP[c]\n",
    "    d_set = MAP[d]\n",
    "    graph_name = c + '_' + d\n",
    "    print(graph_name)\n",
    "    \n",
    "    print(f'### {c}-{d} ###')\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\n",
    "        'source',\n",
    "        'target',\n",
    "        'number_of_paths',\n",
    "        'number_of_concordant_paths',\n",
    "        'in_clinical_trial',\n",
    "        'number_of_concordant_activatory_paths',\n",
    "        'number_of_concordant_inhibitory_paths',\n",
    "        'subgraph_size',\n",
    "        'number_of_unique_nodes',\n",
    "        'lmax',\n",
    "        'subgraph_name',\n",
    "    ])\n",
    "    \n",
    "    if not os.path.exists(os.path.join(DATA_DIR, 'concordant_paths')):\n",
    "        os.mkdir(os.path.join(DATA_DIR, 'concordant_paths'))\n",
    "    \n",
    "    NAME = f'{graph_name}-.tsv'\n",
    "    file_path = os.path.join(DATA_DIR, 'concordant_paths', NAME)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        continue\n",
    "        \n",
    "    # Iterating different chemical-disease pair\n",
    "    final_data = {\n",
    "        'drug': df,\n",
    "        'disease': df\n",
    "    }\n",
    "        \n",
    "    for gname in ['openbio', 'custom']:\n",
    "        if gname == 'openbio':\n",
    "            flag = True\n",
    "            kg_df = openbiolink_df\n",
    "        else:\n",
    "            flag = False\n",
    "            kg_df = custom_df\n",
    "        \n",
    "        paths = get_paths(\n",
    "            graph_df=kg_df,\n",
    "            disease_dict=d_set[gname],\n",
    "            chemical_dict=c_set[gname],\n",
    "            graph_name=graph_name,\n",
    "            openbio=flag\n",
    "        )\n",
    "        \n",
    "        if paths is None:\n",
    "            continue\n",
    "        \n",
    "        graph_copy = create_graph_from_df(kg_df)\n",
    "        graph = graph_copy.copy()\n",
    "\n",
    "        for lmax, p_dict in tqdm(paths.items(), desc='Calculating concordance'):\n",
    "            for p in p_dict:\n",
    "                if len(p['paths']) > 0:\n",
    "                    # Just get the nodes from the path\n",
    "                    tmp_paths = []\n",
    "                    for v, l in p['paths'].items():\n",
    "                        pth = []\n",
    "                        for k in l:\n",
    "                            if k in ['-|', '->']:\n",
    "                                continue\n",
    "                            else:\n",
    "                                pth.append(k)\n",
    "                        tmp_paths.append(pth)\n",
    "\n",
    "                    chemical = p['source']\n",
    "                    disease = p['target']\n",
    "\n",
    "                    results = get_transcriptomic_paths(\n",
    "                        directed_graph=graph,\n",
    "                        source=chemical,\n",
    "                        target=disease,\n",
    "                        all_paths=tmp_paths,\n",
    "                        drug_dict=c_set[gname][chemical],\n",
    "                        disease_dict=d_set[gname][disease],\n",
    "                        clinical_pair_dict=clinical_pair_dict,\n",
    "                        drug_indication_dict=indication_pair_dict,\n",
    "                    )\n",
    "                    \n",
    "                    # For drug data\n",
    "                    for i in ['drug_paths', 'disease_paths']:\n",
    "                        concordant_num = len(results[i])\n",
    "                        if concordant_num != 0:\n",
    "                            activated_paths, inhibited_paths = get_path_count(\n",
    "                                directed_graph=graph,\n",
    "                                filtered_paths=results[i]\n",
    "                            )\n",
    "                            \n",
    "                            new_results = {\n",
    "                                'source': results['source'],\n",
    "                                'target': results['target'],\n",
    "                                'number_of_paths': results['number_of_paths'],\n",
    "                                'number_of_concordant_paths': concordant_num,\n",
    "                                'in_clinical_trial': results['in_clinical_trial'],\n",
    "                                'number_of_concordant_activatory_paths': activated_paths,\n",
    "                                'number_of_concordant_inhibitory_paths': inhibited_paths,\n",
    "                                'subgraph_size': results['subgraph_size'],\n",
    "                                'number_of_unique_nodes': results['number_of_unique_nodes'],\n",
    "                                'lmax': lmax,\n",
    "                                'subgraph_name': gname,\n",
    "                            }\n",
    "\n",
    "                            tmp_df = pd.DataFrame(new_results, index=[0])\n",
    "                            if i == 'drug_paths':\n",
    "                                final_data['drug'] = pd.concat(\n",
    "                                    [final_data['drug'], tmp_df],\n",
    "                                    ignore_index=True\n",
    "                                )\n",
    "                            else:\n",
    "                                final_data['disease'] = pd.concat(\n",
    "                                    [final_data['disease'], tmp_df],\n",
    "                                    ignore_index=True\n",
    "                                )\n",
    "                        \n",
    "    for i, val in final_data.items():\n",
    "        n_file_path = os.path.join(DATA_DIR, 'concordant_paths', f'{graph_name}-{i}.tsv')\n",
    "        val.to_csv(n_file_path, sep='\\t', index=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
