{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "green-volunteer",
   "metadata": {},
   "source": [
    "# Path analysis\n",
    "\n",
    "This notebook contains the statistical analysis of pathways for each lmax in each of the dataset pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-leeds",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dying-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import DATA_DIR, filter_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-proposal",
   "metadata": {},
   "source": [
    "# Convert dict to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceramic-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-shape",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1000_target-lmax_6-openbio.json\n",
      "creed_target-lmax_3-custom.json\n",
      "l1000_target-lmax_3-custom.json\n",
      "creed_geo-lmax_3-custom.json\n",
      "creed_target-lmax_6-openbio.json\n",
      "l1000_geo-lmax_6-openbio.json\n",
      "l1000_target-lmax_7-openbio.json\n",
      "creed_geo-lmax_6-custom.json\n",
      "l1000_geo-lmax_7-openbio.json\n",
      "creed_target-lmax_7-openbio.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 10/40 [01:55<05:46, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1000_target-lmax_6-custom.json\n",
      "creed_target-lmax_6-custom.json\n",
      "l1000_geo-lmax_4-custom.json\n",
      "creed_target-lmax_5-custom.json\n",
      "l1000_target-lmax_5-custom.json\n",
      "l1000_geo-lmax_7-custom.json\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(os.listdir(os.path.join(DATA_DIR, 'lmax-pairs'))):\n",
    "    print(file)\n",
    "    if file in ['l1000_geo-lmax_7-openbio.json', 'l1000_target-lmax_7-openbio.json']:\n",
    "        continue\n",
    "    \n",
    "    if 'lmax_8' in file or 'lmax_3' in file or 'lmax_5' in file or 'lmax_4' in file or 'lmax_6' in file:\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join(DATA_DIR, 'lmax-pairs', file)) as f:\n",
    "        data_dict = json.load(f)\n",
    "\n",
    "    if 'lmax_3' in df_dict and 'lmax_3' in file:\n",
    "        df = df_dict['lmax_3']\n",
    "\n",
    "    elif 'lmax_4' in df_dict and 'lmax_4' in file:\n",
    "        df = df_dict['lmax_4']\n",
    "\n",
    "    elif 'lmax_5' in df_dict and 'lmax_5' in file:\n",
    "        df = df_dict['lmax_5']\n",
    "\n",
    "    elif 'lmax_6' in df_dict and 'lmax_6' in file:\n",
    "        df = df_dict['lmax_6']\n",
    "        \n",
    "\n",
    "    elif 'lmax_7' in df_dict and 'lmax_7' in file:\n",
    "        df = df_dict['lmax_7']\n",
    "\n",
    "    elif 'lmax_8' in df_dict and 'lmax_8' in file:\n",
    "        df = df_dict['lmax_8']\n",
    "\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=[\n",
    "            'source', \n",
    "            'target', \n",
    "            'number_of_paths', \n",
    "            'subgraph_name',\n",
    "            'paths',\n",
    "            'signs'\n",
    "        ])\n",
    "\n",
    "    if 'custom' in file:\n",
    "        subgraph_name = 'custom'\n",
    "    elif 'openbio' in file:\n",
    "        subgraph_name = 'openbio'\n",
    "\n",
    "    for el in data_dict:\n",
    "        if el:\n",
    "\n",
    "            tmp_paths = []\n",
    "            tmp_signs = []\n",
    "            \n",
    "            if len(el['paths']) > 0:\n",
    "                for l, v in el['paths'].items():\n",
    "                    p = []\n",
    "                    ps = []\n",
    "                    for k in v:\n",
    "                        if k == '-|':\n",
    "                            ps.append(-1)\n",
    "                        elif k == '->':\n",
    "                            ps.append(1)\n",
    "                        else:\n",
    "                            p.append(k)\n",
    "                    tmp_paths.append(p)\n",
    "                    tmp_signs.append(ps)\n",
    "\n",
    "                tmp_dict = {\n",
    "                    'source': [el['source']],\n",
    "                    'target': [el['target']], \n",
    "                    'number_of_paths': [len(el['paths'])], \n",
    "                    'subgraph_name': [subgraph_name],\n",
    "                    'paths': [tmp_paths],\n",
    "                    'signs': [tmp_signs]\n",
    "                }\n",
    "            else:\n",
    "                tmp_dict = {\n",
    "                    'source': [el['source']],\n",
    "                    'target': [el['target']], \n",
    "                    'number_of_paths': [len(el['paths'])], \n",
    "                    'subgraph_name': [subgraph_name],\n",
    "                    'paths': [''],\n",
    "                    'signs': ['']\n",
    "                }\n",
    "\n",
    "            tmp_df = pd.DataFrame.from_dict(tmp_dict)\n",
    "            df = pd.concat([df, tmp_df], ignore_index=True)\n",
    "\n",
    "    if 'lmax_3' in file:\n",
    "        df_dict['lmax_3'] = df\n",
    "    elif 'lmax_4' in file:\n",
    "        df_dict['lmax_4'] = df\n",
    "    elif 'lmax_5' in file:\n",
    "        df_dict['lmax_5'] = df\n",
    "    elif 'lmax_6' in file:\n",
    "        df_dict['lmax_6'] = df\n",
    "    elif 'lmax_7' in file:\n",
    "        df_dict['lmax_7'] = df\n",
    "    else:\n",
    "        df_dict['lmax_8'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "guilty-context",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lmax_7':                          source         target number_of_paths subgraph_name  \\\n",
       " 0         pubchem.compound:5152  mondo:0018874             278       openbio   \n",
       " 1         pubchem.compound:5152  mondo:0006639              62       openbio   \n",
       " 2         pubchem.compound:5152  mondo:0004975               2       openbio   \n",
       " 3         pubchem.compound:5152  mondo:0010311               0       openbio   \n",
       " 4         pubchem.compound:5152  mondo:0004985               9       openbio   \n",
       " ...                         ...            ...             ...           ...   \n",
       " 52255  pubchem.compound:5328940  mondo:0021636            1696       openbio   \n",
       " 52256  pubchem.compound:5328940  mondo:0005105            4467       openbio   \n",
       " 52257  pubchem.compound:5328940  mondo:0008315             939       openbio   \n",
       " 52258  pubchem.compound:5328940  mondo:0004948             735       openbio   \n",
       " 52259  pubchem.compound:5328940  mondo:0005061            2098       openbio   \n",
       " \n",
       "                                                    paths  \\\n",
       " 0      [[pubchem.compound:5152, ncbigene:3586, ncbige...   \n",
       " 1      [[pubchem.compound:5152, ncbigene:1843, ncbige...   \n",
       " 2      [[pubchem.compound:5152, ncbigene:3586, ncbige...   \n",
       " 3                                                          \n",
       " 4      [[pubchem.compound:5152, ncbigene:3586, ncbige...   \n",
       " ...                                                  ...   \n",
       " 52255  [[pubchem.compound:5328940, ncbigene:1445, ncb...   \n",
       " 52256  [[pubchem.compound:5328940, ncbigene:11200, nc...   \n",
       " 52257  [[pubchem.compound:5328940, ncbigene:1017, ncb...   \n",
       " 52258  [[pubchem.compound:5328940, ncbigene:25, ncbig...   \n",
       " 52259  [[pubchem.compound:5328940, ncbigene:2066, ncb...   \n",
       " \n",
       "                                                    signs  \n",
       " 0      [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, -1, 1], [1, ...  \n",
       " 1      [[1, -1, -1, 1], [1, 1, 1, -1, 1], [1, -1, 1, ...  \n",
       " 2             [[1, -1, -1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]  \n",
       " 3                                                         \n",
       " 4      [[1, -1, -1, 1, -1, 1], [1, 1, -1, -1, 1], [1,...  \n",
       " ...                                                  ...  \n",
       " 52255  [[-1, 1, 1, 1, -1, 1], [-1, -1, -1, 1, 1, 1], ...  \n",
       " 52256  [[-1, 1, 1, -1, 1], [-1, -1, 1, -1, -1, 1], [-...  \n",
       " 52257  [[-1, 1, -1, -1, 1], [-1, -1, 1, -1, -1, 1], [...  \n",
       " 52258  [[-1, -1, -1, -1, -1, 1], [-1, 1, -1, 1, -1, 1...  \n",
       " 52259  [[-1, 1, 1, -1, -1, 1], [-1, 1, -1, -1, 1, 1],...  \n",
       " \n",
       " [52260 rows x 6 columns]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-turtle",
   "metadata": {},
   "source": [
    "# Saving lmax df to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(DATA_DIR, 'lmax-dfs')):\n",
    "    os.mkdir(os.path.join(DATA_DIR, 'lmax-dfs'))\n",
    "    \n",
    "for lmax in df_dict:\n",
    "    df_dict[lmax].to_csv(\n",
    "        os.path.join(DATA_DIR, 'lmax-dfs', f'{lmax}-data.tsv'), \n",
    "        sep='\\t',\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-instruction",
   "metadata": {},
   "source": [
    "# Path statistic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {\n",
    "    'lmax_3': {},\n",
    "    'lmax_4': {}, \n",
    "    'lmax_5': {}, \n",
    "    'lmax_6': {}, \n",
    "    'lmax_7': {}, \n",
    "    'lmax_8': {}\n",
    "}\n",
    "for lmax in df_dict:  \n",
    "    k = df_dict[lmax]\n",
    "    m = k['number_of_paths'].value_counts().to_dict()\n",
    "\n",
    "    for k, v in m.items():\n",
    "        if k in count_dict[lmax]:\n",
    "            count_dict[lmax][k] += v\n",
    "        else:\n",
    "            count_dict[lmax][k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-aircraft",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for lmax in count_dict:\n",
    "    if count_dict[lmax]:\n",
    "        print(f'\\n #### {lmax} ####')\n",
    "        try:\n",
    "            no_paths = count_dict[lmax][0]\n",
    "        except KeyError:\n",
    "            no_paths = 0\n",
    "            \n",
    "        pairs = list(count_dict[lmax].values())\n",
    "\n",
    "        print(f'No path found for {no_paths} pairs')\n",
    "\n",
    "        print(f'Percentage of no paths - {round((no_paths/sum(pairs)) * 100, 2)}')\n",
    "\n",
    "\n",
    "        m = {k: v for k, v in sorted(count_dict[lmax].items()) if k != 0}\n",
    "        print('\\nNumber of path statitstics')\n",
    "        paths = list(m.keys())\n",
    "        print(f'Maximum - {paths[-1]}, Minimum - {paths[0]}, Mean - {round(sum(paths)/ len(paths), 2)}')\n",
    "\n",
    "        pairs = list(m.values())\n",
    "        print('\\nNumber of pairs statitstics')\n",
    "        print(f'Maximum - {max(pairs)}, Minimum - {min(pairs)}, Mean - {round(sum(pairs)/ len(pairs), 2)}')\n",
    "\n",
    "        max_paths = [k for k,v in m.items() if v == max(pairs)]\n",
    "        min_paths = [k for k,v in m.items() if v == min(pairs)]\n",
    "\n",
    "        print(f'Maximum pair count for path - {len(max_paths)}')\n",
    "        print(f'Minimum pair count for path - {len(min_paths)}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-selection",
   "metadata": {},
   "source": [
    " #### lmax_3 ####\n",
    "No path found for 74658 pairs\n",
    "Percentage of no paths - 97.54\n",
    "\n",
    "Number of path statitstics\n",
    "Maximum - 3, Minimum - 1, Mean - 2.0\n",
    "\n",
    "Number of pairs statitstics\n",
    "Maximum - 1779, Minimum - 12, Mean - 628.67\n",
    "Maximum pair count for path - 1\n",
    "Minimum pair count for path - 1\n",
    "\n",
    " #### lmax_4 ####\n",
    "No path found for 70004 pairs\n",
    "Percentage of no paths - 91.46\n",
    "\n",
    "Number of path statitstics\n",
    "Maximum - 48, Minimum - 1, Mean - 16.74\n",
    "\n",
    "Number of pairs statitstics\n",
    "Maximum - 4018, Minimum - 1, Mean - 210.97\n",
    "Maximum pair count for path - 1\n",
    "Minimum pair count for path - 4\n",
    "\n",
    "#### lmax_5 ####\n",
    "No path found for 57882 pairs\n",
    "Percentage of no paths - 75.62\n",
    "\n",
    "Number of path statitstics\n",
    "Maximum - 943, Minimum - 1, Mean - 183.39\n",
    "\n",
    "Number of pairs statitstics\n",
    "Maximum - 4899, Minimum - 1, Mean - 68.86\n",
    "Maximum pair count for path - 1\n",
    "Minimum pair count for path - 69\n",
    "\n",
    " #### lmax_6 ####\n",
    "No path found for 43619 pairs\n",
    "Percentage of no paths - 56.99\n",
    "\n",
    "Number of path statitstics\n",
    "Maximum - 25621, Minimum - 1, Mean - 1681.37\n",
    "\n",
    "Number of pairs statitstics\n",
    "Maximum - 3389, Minimum - 1, Mean - 23.65\n",
    "Maximum pair count for path - 1\n",
    "Minimum pair count for path - 412\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
